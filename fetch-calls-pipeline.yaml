apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: fetch-calls-pipeline-
  annotations: {pipelines.kubeflow.org/kfp_sdk_version: 1.8.11, pipelines.kubeflow.org/pipeline_compilation_time: '2022-03-21T23:56:06.322560',
    pipelines.kubeflow.org/pipeline_spec: '{"description": "fetches calls from production
      db with respective arguments", "inputs": [{"name": "org_id", "type": "String"},
      {"name": "start_date", "type": "String"}, {"name": "lang", "type": "String"},
      {"name": "end_date", "type": "String"}, {"name": "call_quantity", "type": "Integer"},
      {"name": "call_type", "type": "String"}, {"name": "ignore_callers", "type":
      "String"}, {"name": "reported", "type": "String"}, {"name": "use_case", "type":
      "String"}, {"name": "flow_name", "type": "String"}, {"name": "min_duration",
      "type": "String"}, {"name": "asr_provider", "type": "String"}], "name": "Fetch
      Calls Pipeline"}'}
  labels: {pipelines.kubeflow.org/kfp_sdk_version: 1.8.11}
spec:
  entrypoint: fetch-calls-pipeline
  templates:
  - name: fetch-calls
    container:
      args:
      - --org-id
      - '{{inputs.parameters.org_id}}'
      - --start-date
      - '{{inputs.parameters.start_date}}'
      - --lang
      - '{{inputs.parameters.lang}}'
      - --end-date
      - '{{inputs.parameters.end_date}}'
      - --call-quantity
      - '{{inputs.parameters.call_quantity}}'
      - --call-type
      - '{{inputs.parameters.call_type}}'
      - --ignore-callers
      - '{{inputs.parameters.ignore_callers}}'
      - --reported
      - '{{inputs.parameters.reported}}'
      - --use-case
      - '{{inputs.parameters.use_case}}'
      - --flow-name
      - '{{inputs.parameters.flow_name}}'
      - --min-duration
      - '{{inputs.parameters.min_duration}}'
      - --asr-provider
      - '{{inputs.parameters.asr_provider}}'
      - --on-disk
      - "False"
      - '----output-paths'
      - /tmp/outputs/Output/data
      command:
      - sh
      - -ec
      - |
        program_path=$(mktemp)
        printf "%s" "$0" > "$program_path"
        python3 -u "$program_path" "$@"
      - |
        def fetch_calls(
            org_id,
            start_date,
            lang,
            end_date = None,
            call_quantity = 200,
            call_type = None,
            ignore_callers = None,
            reported = None,
            use_case = None,
            flow_name = None,
            min_duration = None,
            asr_provider = None,
            on_disk = False,
        ):
            import time
            import tempfile
            from datetime import datetime

            from loguru import logger
            from skit_calls import calls, utils, constants as const
            from skit_calls.cli import to_datetime, validate_date_ranges, process_date_filters

            utils.configure_logger(7)

            start_date = to_datetime(start_date)
            if end_date:
                end_date = to_datetime(end_date)
            else:
                end_date = datetime.now()

            validate_date_ranges(start_date, end_date)
            start_date, end_date = process_date_filters(start_date, end_date)

            if not call_quantity:
                call_quantity = const.DEFAULT_CALL_QUANTITY
            if not call_type:
                call_type = const.INBOUND
            if not ignore_callers:
                ignore_callers = const.DEFAULT_IGNORE_CALLERS_LIST

            start = time.time()
            maybe_df = calls.sample(
                org_id,
                start_date,
                end_date,
                lang,
                call_quantity=call_quantity,
                call_type=call_type or None,
                ignore_callers=ignore_callers,
                reported=reported or None,
                use_case=use_case or None,
                flow_name=flow_name or None,
                min_duration=min_duration or None,
                asr_provider=asr_provider or None,
                on_disk=on_disk or False,
            )
            logger.info(f"Finished in {time.time() - start:.2f} seconds")
            if on_disk:
                return maybe_df
            else:
                _, file_path = tempfile.mkstemp(suffix=const.CSV_FILE)
                maybe_df.to_csv(file_path, index=False)
                return file_path

        def _deserialize_bool(s) -> bool:
            from distutils.util import strtobool
            return strtobool(s) == 1

        def _serialize_str(str_value: str) -> str:
            if not isinstance(str_value, str):
                raise TypeError('Value "{}" has type "{}" instead of str.'.format(
                    str(str_value), str(type(str_value))))
            return str_value

        import argparse
        _parser = argparse.ArgumentParser(prog='Fetch calls', description='')
        _parser.add_argument("--org-id", dest="org_id", type=str, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("--start-date", dest="start_date", type=str, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("--lang", dest="lang", type=str, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("--end-date", dest="end_date", type=str, required=False, default=argparse.SUPPRESS)
        _parser.add_argument("--call-quantity", dest="call_quantity", type=int, required=False, default=argparse.SUPPRESS)
        _parser.add_argument("--call-type", dest="call_type", type=str, required=False, default=argparse.SUPPRESS)
        _parser.add_argument("--ignore-callers", dest="ignore_callers", type=str, required=False, default=argparse.SUPPRESS)
        _parser.add_argument("--reported", dest="reported", type=str, required=False, default=argparse.SUPPRESS)
        _parser.add_argument("--use-case", dest="use_case", type=str, required=False, default=argparse.SUPPRESS)
        _parser.add_argument("--flow-name", dest="flow_name", type=str, required=False, default=argparse.SUPPRESS)
        _parser.add_argument("--min-duration", dest="min_duration", type=str, required=False, default=argparse.SUPPRESS)
        _parser.add_argument("--asr-provider", dest="asr_provider", type=str, required=False, default=argparse.SUPPRESS)
        _parser.add_argument("--on-disk", dest="on_disk", type=_deserialize_bool, required=False, default=argparse.SUPPRESS)
        _parser.add_argument("----output-paths", dest="_output_paths", type=str, nargs=1)
        _parsed_args = vars(_parser.parse_args())
        _output_files = _parsed_args.pop("_output_paths", [])

        _outputs = fetch_calls(**_parsed_args)

        _outputs = [_outputs]

        _output_serializers = [
            _serialize_str,

        ]

        import os
        for idx, output_file in enumerate(_output_files):
            try:
                os.makedirs(os.path.dirname(output_file))
            except OSError:
                pass
            with open(output_file, 'w') as f:
                f.write(_output_serializers[idx](_outputs[idx]))
      image: 536612919621.dkr.ecr.ap-south-1.amazonaws.com/vernacular-voice-services/ai/kubeflow/ml-pipeline:master
    inputs:
      parameters:
      - {name: asr_provider}
      - {name: call_quantity}
      - {name: call_type}
      - {name: end_date}
      - {name: flow_name}
      - {name: ignore_callers}
      - {name: lang}
      - {name: min_duration}
      - {name: org_id}
      - {name: reported}
      - {name: start_date}
      - {name: use_case}
    outputs:
      parameters:
      - name: fetch-calls-Output
        valueFrom: {path: /tmp/outputs/Output/data}
      artifacts:
      - {name: fetch-calls-Output, path: /tmp/outputs/Output/data}
    metadata:
      labels:
        pipelines.kubeflow.org/kfp_sdk_version: 1.8.11
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
        pipelines.kubeflow.org/enable_caching: "true"
      annotations: {pipelines.kubeflow.org/component_spec: '{"implementation": {"container":
          {"args": ["--org-id", {"inputValue": "org_id"}, "--start-date", {"inputValue":
          "start_date"}, "--lang", {"inputValue": "lang"}, {"if": {"cond": {"isPresent":
          "end_date"}, "then": ["--end-date", {"inputValue": "end_date"}]}}, {"if":
          {"cond": {"isPresent": "call_quantity"}, "then": ["--call-quantity", {"inputValue":
          "call_quantity"}]}}, {"if": {"cond": {"isPresent": "call_type"}, "then":
          ["--call-type", {"inputValue": "call_type"}]}}, {"if": {"cond": {"isPresent":
          "ignore_callers"}, "then": ["--ignore-callers", {"inputValue": "ignore_callers"}]}},
          {"if": {"cond": {"isPresent": "reported"}, "then": ["--reported", {"inputValue":
          "reported"}]}}, {"if": {"cond": {"isPresent": "use_case"}, "then": ["--use-case",
          {"inputValue": "use_case"}]}}, {"if": {"cond": {"isPresent": "flow_name"},
          "then": ["--flow-name", {"inputValue": "flow_name"}]}}, {"if": {"cond":
          {"isPresent": "min_duration"}, "then": ["--min-duration", {"inputValue":
          "min_duration"}]}}, {"if": {"cond": {"isPresent": "asr_provider"}, "then":
          ["--asr-provider", {"inputValue": "asr_provider"}]}}, {"if": {"cond": {"isPresent":
          "on_disk"}, "then": ["--on-disk", {"inputValue": "on_disk"}]}}, "----output-paths",
          {"outputPath": "Output"}], "command": ["sh", "-ec", "program_path=$(mktemp)\nprintf
          \"%s\" \"$0\" > \"$program_path\"\npython3 -u \"$program_path\" \"$@\"\n",
          "def fetch_calls(\n    org_id,\n    start_date,\n    lang,\n    end_date
          = None,\n    call_quantity = 200,\n    call_type = None,\n    ignore_callers
          = None,\n    reported = None,\n    use_case = None,\n    flow_name = None,\n    min_duration
          = None,\n    asr_provider = None,\n    on_disk = False,\n):\n    import
          time\n    import tempfile\n    from datetime import datetime\n\n    from
          loguru import logger\n    from skit_calls import calls, utils, constants
          as const\n    from skit_calls.cli import to_datetime, validate_date_ranges,
          process_date_filters\n\n    utils.configure_logger(7)\n\n    start_date
          = to_datetime(start_date)\n    if end_date:\n        end_date = to_datetime(end_date)\n    else:\n        end_date
          = datetime.now()\n\n    validate_date_ranges(start_date, end_date)\n    start_date,
          end_date = process_date_filters(start_date, end_date)\n\n    if not call_quantity:\n        call_quantity
          = const.DEFAULT_CALL_QUANTITY\n    if not call_type:\n        call_type
          = const.INBOUND\n    if not ignore_callers:\n        ignore_callers = const.DEFAULT_IGNORE_CALLERS_LIST\n\n    start
          = time.time()\n    maybe_df = calls.sample(\n        org_id,\n        start_date,\n        end_date,\n        lang,\n        call_quantity=call_quantity,\n        call_type=call_type
          or None,\n        ignore_callers=ignore_callers,\n        reported=reported
          or None,\n        use_case=use_case or None,\n        flow_name=flow_name
          or None,\n        min_duration=min_duration or None,\n        asr_provider=asr_provider
          or None,\n        on_disk=on_disk or False,\n    )\n    logger.info(f\"Finished
          in {time.time() - start:.2f} seconds\")\n    if on_disk:\n        return
          maybe_df\n    else:\n        _, file_path = tempfile.mkstemp(suffix=const.CSV_FILE)\n        maybe_df.to_csv(file_path,
          index=False)\n        return file_path\n\ndef _deserialize_bool(s) -> bool:\n    from
          distutils.util import strtobool\n    return strtobool(s) == 1\n\ndef _serialize_str(str_value:
          str) -> str:\n    if not isinstance(str_value, str):\n        raise TypeError(''Value
          \"{}\" has type \"{}\" instead of str.''.format(\n            str(str_value),
          str(type(str_value))))\n    return str_value\n\nimport argparse\n_parser
          = argparse.ArgumentParser(prog=''Fetch calls'', description='''')\n_parser.add_argument(\"--org-id\",
          dest=\"org_id\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--start-date\",
          dest=\"start_date\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--lang\",
          dest=\"lang\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--end-date\",
          dest=\"end_date\", type=str, required=False, default=argparse.SUPPRESS)\n_parser.add_argument(\"--call-quantity\",
          dest=\"call_quantity\", type=int, required=False, default=argparse.SUPPRESS)\n_parser.add_argument(\"--call-type\",
          dest=\"call_type\", type=str, required=False, default=argparse.SUPPRESS)\n_parser.add_argument(\"--ignore-callers\",
          dest=\"ignore_callers\", type=str, required=False, default=argparse.SUPPRESS)\n_parser.add_argument(\"--reported\",
          dest=\"reported\", type=str, required=False, default=argparse.SUPPRESS)\n_parser.add_argument(\"--use-case\",
          dest=\"use_case\", type=str, required=False, default=argparse.SUPPRESS)\n_parser.add_argument(\"--flow-name\",
          dest=\"flow_name\", type=str, required=False, default=argparse.SUPPRESS)\n_parser.add_argument(\"--min-duration\",
          dest=\"min_duration\", type=str, required=False, default=argparse.SUPPRESS)\n_parser.add_argument(\"--asr-provider\",
          dest=\"asr_provider\", type=str, required=False, default=argparse.SUPPRESS)\n_parser.add_argument(\"--on-disk\",
          dest=\"on_disk\", type=_deserialize_bool, required=False, default=argparse.SUPPRESS)\n_parser.add_argument(\"----output-paths\",
          dest=\"_output_paths\", type=str, nargs=1)\n_parsed_args = vars(_parser.parse_args())\n_output_files
          = _parsed_args.pop(\"_output_paths\", [])\n\n_outputs = fetch_calls(**_parsed_args)\n\n_outputs
          = [_outputs]\n\n_output_serializers = [\n    _serialize_str,\n\n]\n\nimport
          os\nfor idx, output_file in enumerate(_output_files):\n    try:\n        os.makedirs(os.path.dirname(output_file))\n    except
          OSError:\n        pass\n    with open(output_file, ''w'') as f:\n        f.write(_output_serializers[idx](_outputs[idx]))\n"],
          "image": "536612919621.dkr.ecr.ap-south-1.amazonaws.com/vernacular-voice-services/ai/kubeflow/ml-pipeline:master"}},
          "inputs": [{"name": "org_id", "type": "String"}, {"name": "start_date",
          "type": "String"}, {"name": "lang", "type": "String"}, {"name": "end_date",
          "optional": true, "type": "String"}, {"default": "200", "name": "call_quantity",
          "optional": true, "type": "Integer"}, {"name": "call_type", "optional":
          true, "type": "String"}, {"name": "ignore_callers", "optional": true, "type":
          "String"}, {"name": "reported", "optional": true, "type": "String"}, {"name":
          "use_case", "optional": true, "type": "String"}, {"name": "flow_name", "optional":
          true, "type": "String"}, {"name": "min_duration", "optional": true, "type":
          "String"}, {"name": "asr_provider", "optional": true, "type": "String"},
          {"default": "False", "name": "on_disk", "optional": true, "type": "Boolean"}],
          "name": "Fetch calls", "outputs": [{"name": "Output", "type": "String"}]}',
        pipelines.kubeflow.org/component_ref: '{}', pipelines.kubeflow.org/arguments.parameters: '{"asr_provider":
          "{{inputs.parameters.asr_provider}}", "call_quantity": "{{inputs.parameters.call_quantity}}",
          "call_type": "{{inputs.parameters.call_type}}", "end_date": "{{inputs.parameters.end_date}}",
          "flow_name": "{{inputs.parameters.flow_name}}", "ignore_callers": "{{inputs.parameters.ignore_callers}}",
          "lang": "{{inputs.parameters.lang}}", "min_duration": "{{inputs.parameters.min_duration}}",
          "on_disk": "False", "org_id": "{{inputs.parameters.org_id}}", "reported":
          "{{inputs.parameters.reported}}", "start_date": "{{inputs.parameters.start_date}}",
          "use_case": "{{inputs.parameters.use_case}}"}'}
  - name: fetch-calls-pipeline
    inputs:
      parameters:
      - {name: asr_provider}
      - {name: call_quantity}
      - {name: call_type}
      - {name: end_date}
      - {name: flow_name}
      - {name: ignore_callers}
      - {name: lang}
      - {name: min_duration}
      - {name: org_id}
      - {name: reported}
      - {name: start_date}
      - {name: use_case}
    dag:
      tasks:
      - name: fetch-calls
        template: fetch-calls
        arguments:
          parameters:
          - {name: asr_provider, value: '{{inputs.parameters.asr_provider}}'}
          - {name: call_quantity, value: '{{inputs.parameters.call_quantity}}'}
          - {name: call_type, value: '{{inputs.parameters.call_type}}'}
          - {name: end_date, value: '{{inputs.parameters.end_date}}'}
          - {name: flow_name, value: '{{inputs.parameters.flow_name}}'}
          - {name: ignore_callers, value: '{{inputs.parameters.ignore_callers}}'}
          - {name: lang, value: '{{inputs.parameters.lang}}'}
          - {name: min_duration, value: '{{inputs.parameters.min_duration}}'}
          - {name: org_id, value: '{{inputs.parameters.org_id}}'}
          - {name: reported, value: '{{inputs.parameters.reported}}'}
          - {name: start_date, value: '{{inputs.parameters.start_date}}'}
          - {name: use_case, value: '{{inputs.parameters.use_case}}'}
      - name: upload2s3
        template: upload2s3
        dependencies: [fetch-calls]
        arguments:
          parameters:
          - {name: fetch-calls-Output, value: '{{tasks.fetch-calls.outputs.parameters.fetch-calls-Output}}'}
          - {name: org_id, value: '{{inputs.parameters.org_id}}'}
  - name: upload2s3
    container:
      args: [--org-id, '{{inputs.parameters.org_id}}', --file-type, untagged, --path-on-disk,
        '{{inputs.parameters.fetch-calls-Output}}']
      command:
      - sh
      - -ec
      - |
        program_path=$(mktemp)
        printf "%s" "$0" > "$program_path"
        python3 -u "$program_path" "$@"
      - |
        def upload2s3(org_id, file_type, path_on_disk):
            import os
            import boto3
            from datetime import datetime
            from loguru import logger

            s3_resource = boto3.client('s3')
            bucket = os.environ["BUCKET"]
            _, ext = os.path.splitext(os.path.basename(path_on_disk))
            upload_path = os.path.join(
                "project",
                str(org_id),
                datetime.now().strftime("%Y-%m-%d"),
                f"{datetime.now().strftime('%Y-%m-%d')}-{file_type}{ext}",
            )
            s3_resource.upload_file(path_on_disk, bucket, upload_path)
            logger.debug(f"Uploaded {path_on_disk} to {upload_path}")

        import argparse
        _parser = argparse.ArgumentParser(prog='Upload2s3', description='')
        _parser.add_argument("--org-id", dest="org_id", type=str, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("--file-type", dest="file_type", type=str, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("--path-on-disk", dest="path_on_disk", type=str, required=True, default=argparse.SUPPRESS)
        _parsed_args = vars(_parser.parse_args())

        _outputs = upload2s3(**_parsed_args)
      image: 536612919621.dkr.ecr.ap-south-1.amazonaws.com/vernacular-voice-services/ai/kubeflow/ml-pipeline:master
    inputs:
      parameters:
      - {name: fetch-calls-Output}
      - {name: org_id}
    metadata:
      labels:
        pipelines.kubeflow.org/kfp_sdk_version: 1.8.11
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
        pipelines.kubeflow.org/enable_caching: "true"
      annotations: {pipelines.kubeflow.org/component_spec: '{"implementation": {"container":
          {"args": ["--org-id", {"inputValue": "org_id"}, "--file-type", {"inputValue":
          "file_type"}, "--path-on-disk", {"inputValue": "path_on_disk"}], "command":
          ["sh", "-ec", "program_path=$(mktemp)\nprintf \"%s\" \"$0\" > \"$program_path\"\npython3
          -u \"$program_path\" \"$@\"\n", "def upload2s3(org_id, file_type, path_on_disk):\n    import
          os\n    import boto3\n    from datetime import datetime\n    from loguru
          import logger\n\n    s3_resource = boto3.client(''s3'')\n    bucket = os.environ[\"BUCKET\"]\n    _,
          ext = os.path.splitext(os.path.basename(path_on_disk))\n    upload_path
          = os.path.join(\n        \"project\",\n        str(org_id),\n        datetime.now().strftime(\"%Y-%m-%d\"),\n        f\"{datetime.now().strftime(''%Y-%m-%d'')}-{file_type}{ext}\",\n    )\n    s3_resource.upload_file(path_on_disk,
          bucket, upload_path)\n    logger.debug(f\"Uploaded {path_on_disk} to {upload_path}\")\n\nimport
          argparse\n_parser = argparse.ArgumentParser(prog=''Upload2s3'', description='''')\n_parser.add_argument(\"--org-id\",
          dest=\"org_id\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--file-type\",
          dest=\"file_type\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--path-on-disk\",
          dest=\"path_on_disk\", type=str, required=True, default=argparse.SUPPRESS)\n_parsed_args
          = vars(_parser.parse_args())\n\n_outputs = upload2s3(**_parsed_args)\n"],
          "image": "536612919621.dkr.ecr.ap-south-1.amazonaws.com/vernacular-voice-services/ai/kubeflow/ml-pipeline:master"}},
          "inputs": [{"name": "org_id", "type": "String"}, {"name": "file_type", "type":
          "String"}, {"name": "path_on_disk", "type": "String"}], "name": "Upload2s3"}',
        pipelines.kubeflow.org/component_ref: '{}', pipelines.kubeflow.org/arguments.parameters: '{"file_type":
          "untagged", "org_id": "{{inputs.parameters.org_id}}", "path_on_disk": "{{inputs.parameters.fetch-calls-Output}}"}'}
  arguments:
    parameters:
    - {name: org_id}
    - {name: start_date}
    - {name: lang}
    - {name: end_date}
    - {name: call_quantity}
    - {name: call_type}
    - {name: ignore_callers}
    - {name: reported}
    - {name: use_case}
    - {name: flow_name}
    - {name: min_duration}
    - {name: asr_provider}
  serviceAccountName: pipeline-runner
